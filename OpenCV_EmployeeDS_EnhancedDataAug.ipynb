{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all necessary libraries\n",
    "import numpy as np\n",
    "import cv2 # opencv\n",
    "import os # control and access the directory structure in local machine\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/rithanya/Documents/Python/faces/Employee_dataset/16_2_2018/') #folder where I unzipped data.zip\n",
    "\n",
    "#OpenCV cascades (xml files) are typically stored at this location\n",
    "#C:\\Users\\<user>\\Miniconda3\\Library\\etc\\haarcascades\n",
    "haarcascades_path = os.listdir('C:/Users/rithanya/Miniconda3/Library/etc/haarcascades/')\n",
    "frontface_alt_cascade = 'C:/Users/rithanya/Miniconda3/Library/etc/haarcascades/haarcascade_frontalface_alt.xml'\n",
    "frontface_default_cascade = 'C:/Users/rithanya/Miniconda3/Library/etc/haarcascades/haarcascade_frontalface_default.xml'\n",
    "frontface_alt2_cascade = 'C:/Users/rithanya/Miniconda3/Library/etc/haarcascades/haarcascade_frontalface_alt2.xml'\n",
    "frontface_alt_tree_cascade = 'C:/Users/rithanya/Miniconda3/Library/etc/haarcascades/haarcascade_frontalface_alt2.xml'\n",
    "\n",
    "lbpcascadesPath = os.listdir(\"C:/Users/rithanya/Miniconda3/Library/etc/lbpcascades/\")\n",
    "\n",
    "lbp_frontface_path = \"C:/Users/rithanya/Miniconda3/Library/etc/lbpcascades/lbpcascade_frontalface.xml\"\n",
    "lbp_fronface_improved_path = \"C:/Users/rithanya/Miniconda3/Library/etc/lbpcascades/lbpcascade_frontalface_improved.xml\"\n",
    "lbp_frontface_profile_path = \"C:/Users/rithanya/Miniconda3/Library/etc/lbpcascades/lbpcascade_profileface.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function to apply differenct cascade function on the images at difference scaleFactor\n",
    "def detect(faceCascade, gray_,  scaleFactor_ = 1.1):\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "                    gray_,\n",
    "                    scaleFactor= scaleFactor_,\n",
    "                    minNeighbors=5,\n",
    "                    minSize=(30, 30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that iterates thru the images in the celebrityfaces dataset and detects faces. Finally it\n",
    "# ... only displays those images that it can't detect the faces.\n",
    "lbp_frontfaceCascade = cv2.CascadeClassifier(lbp_frontface_path)\n",
    "lbp_fronfaceimprovedCascade = cv2.CascadeClassifier(lbp_fronface_improved_path)\n",
    "lbp_profileCascade = cv2.CascadeClassifier(lbp_frontface_profile_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to do data augumentation on images\n",
    "def imgaug(img):\n",
    "    #          Rotate process\n",
    "    img_list = []\n",
    "\n",
    "\n",
    "    #code to rotate the image\n",
    "    ang_range=60\n",
    "    rows,cols = img.shape\n",
    "    ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
    "    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n",
    "    img_rotate = cv2.warpAffine(img,Rot_M,(cols,rows))\n",
    "    img_list.append(img_rotate)\n",
    "\n",
    "    #code to flip the image\n",
    "    img_flip = cv2.flip(img, 1)\n",
    "    img_list.append(img_flip)\n",
    "\n",
    "    #code to do shear\n",
    "\n",
    "    #code to do distortion\n",
    "\n",
    "    return img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee_dataset/lalitha/Snapshot_20180208_83.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_83_aug1.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_83_aug2.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_84.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_84_aug3.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_84_aug4.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_85.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_85_aug5.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_85_aug6.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_86.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_86_aug7.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_86_aug8.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_87.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_87_aug9.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_87_aug10.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_88.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_88_aug11.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_88_aug12.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_89.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_89_aug13.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_89_aug14.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_90.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_90_aug15.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_90_aug16.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_91.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_91_aug17.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_91_aug18.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_92.JPG\n",
      "Employee_dataset/lalitha/Snapshot_20180208_92_aug19.jpg\n",
      "Employee_dataset/lalitha/Snapshot_20180208_92_aug20.jpg\n"
     ]
    }
   ],
   "source": [
    "# Code to perform data augumentation for different employees\n",
    "from os.path import basename\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_folder_path = 'Employee_dataset/lalitha'\n",
    "i = 0\n",
    "for filename in os.listdir(img_folder_path):# iterate thru each image in the employee folder\n",
    "    filename = img_folder_path + '/' + filename # build the path to the image file\n",
    "    if(filename.lower().endswith('.jpg')):\n",
    "       #reading and displaying the original\n",
    "        print(filename)\n",
    "        img = cv2.imread(filename,0) # read the image using OpenCV\n",
    "        #plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "\n",
    "        img_list = imgaug(img)\n",
    "        \n",
    "        for pic in img_list:\n",
    "            i = i + 1\n",
    "            save_path = img_folder_path + \"/\" + os.path.basename(filename).split('.')[0] +\"_aug\" + str(i) +\".jpg\"\n",
    "            print(save_path)\n",
    "            cv2.imwrite(save_path, pic)\n",
    "            continue\n",
    "            plt.imshow(pic, cmap = 'gray', interpolation = 'bicubic')\n",
    "            plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "            plt.show()\n",
    "    continue\n",
    "#continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to detect face using OpenCV\n",
    "def detect_face(img, face_cascade):\n",
    "    #convert the test image to gray scale as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow: Haar classifier\n",
    "    #face_cascade = cv2.CascadeClassifier('opencv-files/lbpcascade_frontalface.xml')\n",
    "\n",
    "    #let's detect multiscale images(some images may be closer to camera than others)\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5);\n",
    "\n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "\n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "\n",
    "    #return only the face part of the image\n",
    "    return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "#of faces and another list of labels for each face\n",
    "def prepare_training_data(trainfolder = './'):\n",
    "    \n",
    "    #list to hold all subject faces\n",
    "    faces = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "    label_names = ['']\n",
    "    total_images = 0\n",
    "    #lbp_frontfaceCascade = cv2.CascadeClassifier(lbp_frontface_path)\n",
    "    haar_faceCascade_default = cv2.CascadeClassifier(frontface_default_cascade)\n",
    "    haar_frontface_alt = cv2.CascadeClassifier(frontface_alt_cascade)\n",
    "    #detected_images = []\n",
    "    for imgfolder in [name for name in os.listdir(trainfolder) if os.path.isdir(name)]: #iterate thru each of the 5 celeb folders\n",
    "        if(imgfolder != '.DS_Store'):\n",
    "            label_names.append(imgfolder)\n",
    "            #print(imgfolder)\n",
    "            #for filename in os.listdir(trainfolder + imgfolder + \"/samples\"):# iterate thru each image in a celeb folder\n",
    "            #    filename = trainfolder + imgfolder + '/samples/' + filename # build the path to the image file\n",
    "            for filename in os.listdir(trainfolder + imgfolder ):# iterate thru each image in a celeb folder\n",
    "                filename = trainfolder + imgfolder + '/' + filename # build the path to the image file\n",
    "                if(filename.lower().endswith('.jpg')):\n",
    "                    print(filename.split('.')[0])\n",
    "                    face = cv2.imread(filename) # read the image using OpenCV\n",
    "                    #add face to list of faces\n",
    "                    if(face is not None):\n",
    "                        gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                        #continue\n",
    "                        total_images = total_images + 1\n",
    "                        faces.append(gray)\n",
    "                        #add label for this face\n",
    "                        labels.append(label_names.index(imgfolder))\n",
    "                        \n",
    "                    #print(label_names.index(imgfolder))\n",
    "                    continue\n",
    "\n",
    "                    plt.imshow(face, cmap = 'gray', interpolation = 'bicubic') # display all images read\n",
    "                    plt.xticks([]), plt.yticks([])\n",
    "                    plt.show()\n",
    "    return faces, labels, label_names, total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "akash\n",
      "aravind\n",
      "Arun_S\n",
      "Dinesh_Nagarajan\n",
      "gowtham\n",
      "harini\n",
      "Jeffrey_Rajan\n",
      "karthick_aravindan\n",
      "karthic_chandran\n",
      "Karthik\n",
      "keerthana\n",
      "lalitha\n",
      "Mani\n",
      "Ragav\n",
      "Saravanan\n",
      "Steve\n",
      "Data prepared\n",
      "Detected faces:  291\n",
      "Detected labels:  291\n",
      "Total Images:  291\n"
     ]
    }
   ],
   "source": [
    "#code to load the dataset and detect the faces and labels for training\n",
    "print(\"Preparing data...\")\n",
    "\n",
    "faces, labels, label_names, total_images = prepare_training_data('./')\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#print total faces and labels\n",
    "print(\"Detected faces: \", len(faces))\n",
    "print(\"Detected labels: \", len(labels))\n",
    "print(\"Total Images: \", total_images)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw rectangle on image \n",
    "#according to given (x, y) coordinates and \n",
    "#given width and heigh\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    " \n",
    "#function to draw text on give image starting from\n",
    "#passed (x, y) coordinates. \n",
    "def draw_text(img, text, x, y):\n",
    "     cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to perform cross validation on the training set to get training score...\n",
    "def cross_val(cv = 5):\n",
    "    scores = []\n",
    "    while(cv > 0):\n",
    "        cv = cv - 1\n",
    "        from sklearn.cross_validation import train_test_split\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(faces, labels)\n",
    "        print(len(Xtrain))\n",
    "        print(len(Xtest))\n",
    "        #print(ytrain)\n",
    "        #print(ytest)\n",
    "        face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        face_recognizer.train(Xtrain, np.array(ytrain))\n",
    "        test_labels = []\n",
    "        pred_labels = []\n",
    "        i = -1\n",
    "        for face in Xtest:\n",
    "            i = i + 1\n",
    "            label = face_recognizer.predict(face)\n",
    "            label_text = label_names[label[0]]\n",
    "            #face, label = predict_train(face)\n",
    "            #print(label_names)\n",
    "            #print(ytest[i])\n",
    "            test_labels.append(label_names[ytest[i]])\n",
    "            pred_labels.append(label_text)\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        scores.append(accuracy_score(test_labels, pred_labels))\n",
    "    return scores\n",
    "\n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #print(confusion_matrix(test_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation to get Training Score...\n",
      "1110\n",
      "371\n",
      "1110\n",
      "371\n",
      "[0.9703504043126685, 0.95687331536388143]\n",
      "0.963611859838\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validation to get Training Score...')\n",
    "scores =  cross_val(2)\n",
    "print (scores)\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'akash', 'aravind', 'Arun_S', 'Dinesh_Nagarajan', 'gowtham', 'harini', 'Jeffrey_Rajan', 'karthick_aravindan', 'karthic_chandran', 'Karthik', 'keerthana', 'lalitha', 'Mani', 'Saravanan', 'Steve']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#code to persist the trained model to use it later\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(faces, np.array(labels))\n",
    "face_recognizer.write('C:/Users/rithanya/Documents/Python/faces/HackObsV1.yml')\n",
    "face_recognizer2 = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer2.read('C:/Users/rithanya/Documents/Python/faces/HackObsV1.yml')\n",
    "\n",
    "test_labels = []\n",
    "pred_labels = []\n",
    "print(label_names)\n",
    "i = -1\n",
    "for face in faces:\n",
    "    i = i + 1\n",
    "    label = face_recognizer2.predict(face)\n",
    "    pred_labels.append(label[0])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
